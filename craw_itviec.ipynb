{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9672c332-48de-462f-a755-1e34311f1d92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import traceback\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b6291c4-418f-4156-9e0a-0c3922e9885e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--incognito\")\n",
    "chrome_options.add_argument(\"--window-size=1920x1080\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aca0754a-8e2d-40d3-80cf-4619aba0c269",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26556/688692109.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(chrome_options=chrome_options, executable_path=\"chrome/chromedriver\")\n",
      "/tmp/ipykernel_26556/688692109.py:1: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(chrome_options=chrome_options, executable_path=\"chrome/chromedriver\")\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(chrome_options=chrome_options, executable_path=\"chrome/chromedriver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8dee74d-9b7d-459a-87d3-783b9f6abcc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "querys = [\n",
    "    'AI',\n",
    "    'data scientist',\n",
    "    'data engineer',\n",
    "    'data analytic',\n",
    "    'backend',\n",
    "    'mobile',\n",
    "    'devops',\n",
    "    'tester',\n",
    "    'qa',\n",
    "    'software'\n",
    "]\n",
    "citys = [\n",
    "    'All Cities'\n",
    "]\n",
    "query = querys[0]\n",
    "city = citys[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f5c0149-f839-4567-a597-0f9a3a884a7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26556/3791082140.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(chrome_options=chrome_options, executable_path=\"chrome/chromedriver\")\n",
      "/tmp/ipykernel_26556/3791082140.py:2: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(chrome_options=chrome_options, executable_path=\"chrome/chromedriver\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sign_in = True\n",
    "driver = webdriver.Chrome(chrome_options=chrome_options, executable_path=\"chrome/chromedriver\")\n",
    "\n",
    "if sign_in:\n",
    "    url = \"https://itviec.com/sign_in\"\n",
    "    driver.get(url)\n",
    "    web_email = driver.find_element(value='user_email')\n",
    "    web_email.send_keys('21C29003@student.hcmus.edu.vn')\n",
    "    web_pass = driver.find_element(value='user_password')\n",
    "    web_pass.send_keys('ABCdef@123456')\n",
    "    web_button = driver.find_element(by=By.CLASS_NAME, value='btn-danger')\n",
    "    time.sleep(1.)\n",
    "    web_button.submit()\n",
    "    web_button = driver.find_element(by=By.CLASS_NAME, value = 'swal2-close')\n",
    "    time.sleep(1.5)\n",
    "    web_button.click()\n",
    "    time.sleep(1.5)\n",
    "else:\n",
    "    url = \"https://itviec.com/\"\n",
    "    driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21950cd5-8adb-42f1-bd6d-fa52f7d9202b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawl AI ...\n",
      "web_job click fail\n",
      "web_job click fail2\n",
      "web_job click fail\n",
      "web_job click fail2\n",
      "fail first\n",
      "done\n",
      "Done data scientist\n",
      "Crawl data engineer ...\n",
      "fail first\n",
      "done\n",
      "Crawl data analytic ...\n",
      "fail first\n",
      "done\n",
      "Crawl backend ...\n",
      "web_job click fail\n",
      "web_job click fail2\n",
      "web_job click fail\n",
      "web_job click fail2\n",
      "web_job click fail\n",
      "web_job click fail2\n",
      "web_job click fail\n",
      "web_job click fail2\n",
      "web_job click fail\n",
      "web_job click fail2\n",
      "web_job click fail\n",
      "web_job click fail2\n",
      "web_job click fail\n",
      "web_job click fail2\n",
      "web_job click fail\n",
      "web_job click fail2\n",
      "web_job click fail\n",
      "web_job click fail2\n",
      "fail first\n",
      "done\n",
      "Crawl mobile ...\n",
      "web_job click fail\n",
      "web_job click fail2\n",
      "web_job click fail\n",
      "web_job click fail2\n",
      "web_job click fail\n",
      "web_job click fail2\n",
      "fail first\n",
      "done\n",
      "Crawl devops ...\n",
      "web_job click fail\n",
      "web_job click fail\n",
      "web_job click fail\n",
      "web_job click fail\n",
      "web_job click fail\n",
      "web_job click fail\n",
      "fail first\n",
      "done\n",
      "Crawl tester ...\n",
      "web_job click fail\n",
      "fail first\n",
      "done\n",
      "Crawl qa ...\n",
      "web_job click fail\n",
      "web_job click fail\n",
      "fail first\n",
      "done\n",
      "Crawl software ...\n",
      "web_job click fail\n",
      "fail first\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "job_urls = set()\n",
    "\n",
    "for query in querys:\n",
    "    if os.path.exists(f'raw_data/{query}.csv'):\n",
    "        print(f'Done {query}')\n",
    "        continue\n",
    "    print(f'Crawl {query} ...')\n",
    "    url = \"https://itviec.com/\"\n",
    "    driver.get(url)\n",
    "\n",
    "    web_city = driver.find_element(by=By.XPATH, value=\"//*[@class='search-form__city-section rounded']\")\n",
    "    web_city.click()\n",
    "    time.sleep(2)\n",
    "    driver.find_element(value='city-ts-dropdown').find_element(by=By.XPATH, value=f\"//div[text()='{city}']\").click()\n",
    "\n",
    "    web_query = driver.find_element(value='query')\n",
    "    web_query.send_keys(query)\n",
    "    web_query.send_keys(Keys.ENTER)\n",
    "\n",
    "\n",
    "    job_infos = []\n",
    "    while True:\n",
    "        time.sleep(1)\n",
    "        web_group_job = driver.find_element(by=By.CLASS_NAME, value='first-group')\n",
    "        web_jobs = web_group_job.find_elements(By.XPATH, \"./div[starts-with(@class, 'job')]\")\n",
    "        k = 0\n",
    "\n",
    "        time.sleep(1)\n",
    "        for web_job in web_jobs:\n",
    "            # try:\n",
    "                job_url = web_job.find_elements(by=By.CLASS_NAME, value='job-details-link-wrapper')[1].find_element(by=By.XPATH, value='.//a').get_attribute('href')\n",
    "                # if job_url in job_urls:\n",
    "                #     continue\n",
    "                # else: job_urls.add(job_url)\n",
    "\n",
    "                job_info = {'query':query}\n",
    "                k += 1\n",
    "                time.sleep(2.5)\n",
    "                try:\n",
    "                    web_job.click()\n",
    "                except Exception as e:\n",
    "                    print('web_job click fail')\n",
    "                    try:\n",
    "                        web_job.click()\n",
    "                    except Exception as e:\n",
    "                        print('web_job click fail2')\n",
    "                        continue\n",
    "                    continue\n",
    "                time.sleep(2.5)\n",
    "\n",
    "                s = time.time()\n",
    "                web_job_detail = driver.find_element(by=By.CLASS_NAME, value='job-details--show-employer')\n",
    "                job_title = web_job_detail.find_element(by=By.CLASS_NAME, value='job-details__title').text\n",
    "                job_tags = [x.text for x in web_job_detail.find_elements(by=By.CLASS_NAME, value='mkt-track')]\n",
    "                job_addresses = []\n",
    "                job_at = None\n",
    "                last_post = None\n",
    "                company_name = None\n",
    "\n",
    "\n",
    "                company_name = driver.find_element(by=By.CLASS_NAME, value='job-details__sub-title').text\n",
    "\n",
    "                job_addresses_ = web_job_detail.find_elements(by=By.CLASS_NAME, value='svg-icon__text')\n",
    "                for job_address in job_addresses_:\n",
    "\n",
    "                    if job_address.find_element(by=By.XPATH, value = '..').get_attribute('class')=='svg-icon__box d-flex align-items-center':\n",
    "                        job_at = job_address.text\n",
    "                    elif len(job_address.find_elements(by=By.XPATH, value = '..//*[name()=\"use\" and @*=\"#location_icon\"]')):\n",
    "                        job_addresses.append(job_address.text[:-8])\n",
    "                    elif len(job_address.find_elements(by=By.XPATH, value = '..//*[name()=\"use\" and @*=\"#calendar_icon\"]')):\n",
    "                        last_post = job_address.text\n",
    "                    else:\n",
    "                        salary = job_address.text\n",
    "                        # print(job_address.find_element(by=By.XPATH, value = '..').get_attribute('class'))\n",
    "\n",
    "                description = None\n",
    "                reason = None\n",
    "                skill = None\n",
    "                why_work=None\n",
    "                for p in web_job_detail.find_elements(by=By.CLASS_NAME, value='job-details__top-reason-to-join-us') + \\\n",
    "                    web_job_detail.find_elements(by=By.CLASS_NAME, value='job-details__paragraph'):\n",
    "                    h2 = p.find_element(by=By.XPATH, value='(preceding-sibling::h2)[last()]').text\n",
    "                    if h2 == 'Top 3 Reasons To Join Us': reason = p.text\n",
    "                    if h2 == 'Job Description': description = p.text\n",
    "                    if h2 == 'Your Skills and Experience': skill = p.text\n",
    "                    if h2 == \"Why You'll Love Working Here\": why_work = p.text\n",
    "\n",
    "\n",
    "                company_url = web_job.find_elements(by=By.CLASS_NAME, value='job-details-link-wrapper')[0].find_element(by=By.XPATH, value='.//a').get_attribute('href')\n",
    "\n",
    "                web_company = driver.find_element(by=By.CLASS_NAME, value='search-page-employer-overview__characteristics')\n",
    "                company_type = None\n",
    "                company_people = None\n",
    "                company_nation = None\n",
    "                company_working_day = None\n",
    "                company_ot = None\n",
    "\n",
    "\n",
    "                company_infos_ = web_company.find_elements(by=By.CLASS_NAME, value='svg-icon__text')\n",
    "                for company_info in company_infos_:\n",
    "                    if len(company_info.find_elements(by=By.XPATH, value = '..//*[name()=\"use\" and @*=\"#setting_icon\"]')):\n",
    "                        company_type = company_info.text\n",
    "                    elif len(company_info.find_elements(by=By.XPATH, value = '..//*[name()=\"use\" and @*=\"#people_icon\"]')):\n",
    "                        company_people = company_info.text\n",
    "                    elif len(company_info.find_elements(by=By.XPATH, value = '..//*[name()=\"use\" and @*=\"#calendar_icon\"]')):\n",
    "                        company_working_day = company_info.text\n",
    "                    elif len(company_info.find_elements(by=By.XPATH, value = '..//*[name()=\"use\" and @*=\"#time_icon\"]')):\n",
    "                        company_ot = company_info.text\n",
    "                    else :\n",
    "                        company_nation = company_info.text\n",
    "\n",
    "                job_info['job_url'] = job_url\n",
    "                job_info['title'] = job_title\n",
    "                job_info['tags'] = job_tags\n",
    "                job_info['address'] = job_addresses\n",
    "                job_info['at'] = job_at\n",
    "                job_info['last_post'] = last_post\n",
    "                job_info['reason'] = reason\n",
    "                job_info['description'] = description\n",
    "                job_info['skill'] = skill\n",
    "                job_info['why_work'] = why_work\n",
    "                job_info['salary'] = salary\n",
    "                job_info['company_url'] = company_url\n",
    "                job_info['company_name'] = company_name\n",
    "                job_info['company_type'] = company_type\n",
    "                job_info['company_people'] = company_people\n",
    "                job_info['company_working_day'] = company_working_day\n",
    "                job_info['company_ot'] = company_ot\n",
    "                job_info['company_nation'] = company_nation\n",
    "                job_infos.append(job_info)\n",
    "                # break\n",
    "            # except Exception as e:\n",
    "            #     print('err')\n",
    "            #     print(traceback.format_exc())\n",
    "            #     pass\n",
    "\n",
    "        # try:\n",
    "        try:\n",
    "            time.sleep(2.)\n",
    "            web_next = driver.find_element(by=By.XPATH, value='//a[@rel=\"next\"]')\n",
    "            web_next.click()\n",
    "            time.sleep(2.)\n",
    "        except Exception as e:\n",
    "            try:\n",
    "                print('fail first')\n",
    "                web_next = driver.find_element(by=By.XPATH, value='//a[@rel=\"next\"]')\n",
    "                web_next.click()\n",
    "                time.sleep(2.)\n",
    "            except Exception as e:\n",
    "                print('done')\n",
    "                break\n",
    "        # except Exception as e:\n",
    "        #     print('Done')\n",
    "        #     break\n",
    "    df = pd.DataFrame(job_infos)\n",
    "    df.to_csv(f'raw_data/{query}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "selenium",
   "language": "python",
   "name": "selenium"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
